Se denominan algoritmos de \textit{clustering} aquellos algoritmos de aprendizaje no supervisado que agrupan los elementos de un conjunto de datos en conjuntos (clusters) de modo que los objetos pertenecientes a un mismo cluster sean más similares que aquellos en clusters distintos.
Su aplicación permite simplificar la estructura del conjunto de datos, convirtiéndolo en uno más pequeño y fácilmente manipulable;
o como en el caso que ocupa este trabajo, encontrar grupos de especial significación para el problema, como pueden ser agrupaciones de segmentos de audio correspondientes a vocalizaciones semejantes de individuos misma especie animal.

% Wikipedia
Los algoritmos de clustering difieren significativamente en su noción de qué constituye un cluster y cómo hallarlos eficientemente.
Algunas de las nociones de cluster más populares incluyen grupos con pequeñas distancias entre sus integrantes, áreas de alta densidad en el espacio de datos, o distribuciones estadísticas particulares.
El algoritmo más apropiado para un problema, así como su configuración de parámetros (incluyendo la función de distancia a emplear, el umbral de densidad o el número de clusters esperado) es altamente dependiente de las características del conjunto de datos y del uso que se desea dar a los resultados obtenidos.

La determinación del número de conjuntos es a menudo un problema en sí;
algunos algoritmos lo hayan como parte de su funcionamiento, mientras que otros requieren dicho valor como entrada.
Al proceso de decisión del algoritmo y la combinación de parámetros de mejor ajuste al problema, se le conoce como \textit{selección del modelo};
y las diferentes medidas para la evaluación de los resultados producidos por un modelo dado, con dicha finalidad, es un tema abordado más adelante en este trabajo.

En las siguientes secciones se analizan los principales algoritmos de clustering empleados en el presente trabajo.

\section{Clustering Particional}\label{sec:clusteringParticional}
\input{chapters/3_clustering/partitional-clustering}

\section{Clustering Jerárquico Aglomerativo}\label{sec:clusteringJerárquicoAglomerativo}
\input{chapters/3_clustering/hierarchical-clustering}

\section{Clustering Basado en Densidad}\label{sec:Dbscan}
\input{chapters/3_clustering/density-clustering}

\section{Clustering Basado en Probabilidades}\label{sec:clusteringBasadoEnProbabilidades}
\input{chapters/3_clustering/probabilistic-clustering}

\section{Clustering Basado en Grafos}\label{sec:graphClustering}
\input{chapters/3_clustering/graph-clustering}

\nomenclature{SSE}{Sum of Square Errors}
\nomenclature{AIC}{Criterio de Información de Akaike (por sus siglas en inglés: Akaike Information Criterion)}
\nomenclature{DBSCAN}{Density-Based Spatial Clustering of Applications with Noise}
\nomenclature{HDBSCAN}{Hierarchical DBSCAN}
\nomenclature{GMM}{Gaussian Mixture Model}
\nomenclature{EM}{Expectation-maximization}
\nomenclature{BIC}{Criterio de Información Bayesiano (por sus siglas en inglés: Bayesian Information Criterion)}

