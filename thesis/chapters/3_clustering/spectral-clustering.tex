Los algoritmos de \textit{clustering espectral}, a diferencia de otros como K-Means o GMM, no generan necesariamente clusters de estructura convexa, por lo que pueden aplicarse en situaciones de mayor complejidad.

Un algoritmo de clustering espectral se basa en el análisis del espectro (vectores propios) de la matriz laplaciana correspondiente a las similitudes (o distancias) del conjunto de datos.

\begin{algorithm}
    \caption{Clustering Espectral}
    \label{algorithm:SpectralClustering}
    Construir una matriz de similaridad para todos los puntos del conjunto de datos\;
    Convertir el espacio de los puntos a otro, donde se encuentren mejor agrupados, empleando los valores propios de la matriz laplaciana\;
    Emplear un algoritmo de clustering (por ejemplo, K-Means) para particionar la proyección obtenida en el paso anterior\;
\end{algorithm}

A la representación del conjunto de datos obtenida luego del paso 2 se le conoce como \textit{proyección espectral} (\textit{spectral embedding}), y puede asimismo ser empleada con otros fines, como la reducción de dimensiones.

\subsection{Matriz de Similaridad}\label{subsec:matrizDeSimilaridad}

La matriz de similitudes entre los puntos del conjunto de datos suele tomarse como la matriz de adyacencia correspondiente a uno de los siguientes grafos denotados por $G$~\cite{Aggarawal13}:

\begin{enumerate}
    \item \textbf{Grafo de KNN}: Se conectan los puntos $x_i$ y $x_j$ si uno se encuentra entre los $K$ puntos más cercanos al otro.
    La distancia se computa empleando la representación original de los puntos;
    a menudo se utilizan las normas $L_1$ o $L_2$, o la similitud coseno.
    Esto puede hacerse tanto si ambos puntos son $K$-vecinos entre sí, como si uno solo lo es del otro.
    Igualmente el peso de las aristas puede tomarse binario (1 si hay arista, 0 si no) o a partir de la distancia existente entre los puntos.

    \item \textbf{Grafo de $\epsilon$-vecindades}: Dos puntos $x_i$ y $x_j$ se encuentran conectados solo cuando la distancia $|| x_i - x_j ||^2$ es menor que el valor $\epsilon$.

    \item \textbf{Grafo completo}: Todos los puntos con similaridad positiva entre sí son conectados.
    Frecuentemente los pesos de las aristas se definen mediante la función RBF\footnote{\textit{Radial basis function} o \textit{función de base radial} en español.} Gaussiana:
    \[
        W_{ij} = e^{-\sigma \cdot dist(x_i , x_j)^2}
    \]
    donde $dist(x_i , x_j)$ es la distancia euclidiana entre los puntos, y $\sigma$ es un parámetro que determina el decaimiento de la función a medida que los valores se acercan o alejan al 0.
\end{enumerate}

\subsection{Clustering Espectral No Normalizado}\label{subsec:clusteringEspectralNoNormalizado}

Para cada punto $x_i$, su \textit{grado} puede definirse como la suma de los pesos de las aristas incidentes sobre él:

\begin{equation*}
    d_i = \sum_{j=1}^{n}{W_{ij}}
\end{equation*}

A partir de los grados, puede definirse entonces la \textit{matriz de grados} $D$, como la matriz diagonal que satisface $D_{ii}=d_i$.

El \textit{vector indicador} para un subconjunto $A$ de puntos, se denota como $\mathbbm{1}_A = (f_1,\dots,f_n)^T$, donde $f_i = 1$ si $x_i$ pertenece a $A$, y $f_i = 0$ en caso contrario.

La \textit{matriz laplaciana} $L$ se define como:

\begin{equation*}
    L = D - W
\end{equation*}

La matriz laplaciana $L$ cumple las siguientes propiedades~\cite{Luxburg07}:

\begin{enumerate}
    \item Para todo vector $f\in \mathbb{R}^n$, se cumple que
    \[
        f^T Lf = \frac{1}{2}\sum_{i,j=1}^{n}{W_{ij}(f_i - f_j)^2}
    \]
    \item $L$ es simétrica y semidefinida positiva.
    \item El menor valor propio de $L$ es 0, y el vector propio correspondiente es el vector constante uno, $\mathbbm{1}$.
    \item $L$ tiene $n$ valores propios reales no negativos $0=\lambda_1 \leq \lambda_2 \leq \dots \leq \lambda_n$.
\end{enumerate}

Asumiendo que $G$ tiene $K$ componentes conexas $A_1,A_2,\dots,A_K$, en tal caso, sin perder la generalidad, puede representarse $L$ como una matriz diagonal de bloques:

\begin{equation*}
    L =
    \begin{bmatrix}
        L_1 & & &     \\
        & L_2 & &     \\
        & & \ddots &     \\
        & & & L_K
    \end{bmatrix}
\end{equation*}

Dado que $L$ es una matriz diagonal de bloques, su espectro está dado por la unión de los espectros de las matrices $L_i$, de forma que sus vectores propios estarán dados por el conjunto de los de cada una de las matrices $L_i$, con ceros en las posiciones correspondientes a los demás bloques.
Luego por la propiedad 3, se tiene que cada $L_i$ tiene un valor propio 0, que tiene asociado un vector propio con 1 en la i-ésima componente y 0 en las restantes.
Por tanto, la matriz $L$ tiene tantos valores propios 0 como componentes conexas existan en el grafo $G$.

