Frecuentemente sucede que un número de grande de dimensiones en la representación del conjunto de datos, lejos de aportar un beneficio en su procesamiento, dificulta la tarea y conlleva a resultados donde la presencia de <<ruido>>\footnote{La existencia de ruido en un conjunto de datos suele deberse a imperfecciones de las tecnologías empleadas para confeccionarlo, así como a la naturaleza del origen de los propios datos (por ejemplo, la grabación de sonidos en un ambiente donde varias vocalizaciones animales se solapan entre ellas y con otros sonidos de origen natural como los del viento y la lluvia).} en los datos produce errores.
El uso de conjuntos de datos de alta dimensionalidad casi siempre suma, por tanto, tiempo adicional a la ejecución de los algoritmos y errores a sus respuestas.
Por otra parte, el análisis de los datos por parte de seres humanos se dificulta cuando estos sobrepasan las dos o tres dimensiones, especialmente porque se imposibilita el uso de gráficas para visualizar su comportamiento.
De ahí que se haga muy compleja la interpretación por parte del usuario de los resultados producidos por un algoritmo (especialmente los \textit{no supervisados}).

Para dar solución a las problemáticas mencionadas, se desarrollaron las técnicas de \textit{reducción de dimensiones}, que se proponen eliminar atributos irrelevantes o con significativa presencia de ruido, así como aquellos que solo aportan información redundante.

\section{Análisis de Componentes Principales}\label{subsec:PCA}
\input{chapters/2_dimensionality_reduction/principal-component-analysis}

%\section{Manifold Learning}\label{sec:manifoldLearning}
%\input{chapters/2_dimensionality_reduction/manifold-learning}